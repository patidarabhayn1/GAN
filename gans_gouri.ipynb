{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "input_dims = 100\n",
    "epochs = 1000\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Dataloader preparing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize((128  , 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5 , 0.5 , 0.5) , (0.5 , 0.5 , 0.5))\n",
    "    ])\n",
    "dataset = torchvision.datasets.ImageFolder(\"./dataset/animals\" ,transform=TRANSFORM_IMG)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size= batch_size, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dims , dim = 4):\n",
    "        super(Generator, self).__init__()\n",
    "        def upsample_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(out_channels , out_channels , kernel_size = 3 , stride = 1 , padding = 'same'),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "        self.input_layer = nn.Linear(100 , 64 * 4*4)\n",
    "        self.first = upsample_block(64 , 128)\n",
    "        self.second = upsample_block(128 , 256)\n",
    "        layers = [upsample_block(256 , 256) for _ in range(2)]\n",
    "        self.middle = nn.Sequential(*layers)\n",
    "        self.last = upsample_block(256 , 3)\n",
    "        self.final = nn.Conv2d(3 , 3 , kernel_size = 3 , stride = 1 , padding = 'same')\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = x.view(x.size(0), 64, 4, 4)  # Reshape for ConvTranspose layers\n",
    "        x = self.first(x)\n",
    "        x = self.second(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.last(x)\n",
    "        x = self.final(x)\n",
    "\n",
    "        x = torch.nn.functional.tanh(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, output_dims):\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=4, padding=1)\n",
    "        # self.norm1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=4, padding=1)\n",
    "        # self.norm2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=4, padding=1)\n",
    "        # self.norm3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=4, padding=1)\n",
    "\n",
    "        self.conv4 = nn.utils.spectral_norm(self.conv4)\n",
    "        self.conv3 = nn.utils.spectral_norm(self.conv3)\n",
    "        self.conv2 = nn.utils.spectral_norm(self.conv2)\n",
    "        self.conv1 = nn.utils.spectral_norm(self.conv1)\n",
    "\n",
    "        self.output_layer = nn.Linear(512*1*1, output_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.leaky_relu((self.conv1(x)))\n",
    "        x = torch.nn.functional.leaky_relu((self.conv2(x)))\n",
    "        x = torch.nn.functional.leaky_relu((self.conv3(x)))\n",
    "        x = torch.nn.functional.leaky_relu((self.conv4(x)))\n",
    "        # Global Average Pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, features)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class DCGan(nn.Module):\n",
    "    def __init__(self,input_dims =100, output_dims = 1):\n",
    "        super(DCGan,self).__init__()\n",
    "        self.gen = Generator(input_dims)\n",
    "        self.critic = Critic(output_dims)\n",
    "    def forward(self , latents , images):\n",
    "        x = self.gen(latents)\n",
    "        generated = self.critic(x)\n",
    "        real = self.critic(images) \n",
    "        return real , generated\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCTrainer():\n",
    "    def __init__(self,model , dataloader , optim_gen , optim_critic  , epochs, device ,latent_dims, lambda_ = 5):\n",
    "        self.model = model.to(device)\n",
    "        self.dataloader = dataloader\n",
    "        self.optim_gen = optim_gen \n",
    "        self.optim_critc = optim_critic\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.lambda_ = lambda_\n",
    "        self.latent_dims = latent_dims\n",
    "        self.mvn = torch.distributions.MultivariateNormal( torch.zeros(latent_dims)  , torch.eye(latent_dims) )\n",
    "    \n",
    "    \n",
    "    def latent_sampler(self ,batch_size ):\n",
    "        samples = self.mvn.sample((batch_size,))\n",
    "        return samples\n",
    "    \n",
    "    def W_loss_critic(self , real_y, gen_y,):\n",
    "        real = torch.mean(real_y)\n",
    "        fake = torch.mean(gen_y)\n",
    "        return (fake - real) \n",
    "    \n",
    "    def W_loss_gen(self , gen_y):\n",
    "        return -torch.mean(gen_y)\n",
    "    \n",
    "\n",
    "    def noramlize_weights(self ):\n",
    "        for p in self.model.critic.parameters():\n",
    "            p.data.clamp_(-0.01 ,0.01)\n",
    "\n",
    "    def gradient_penalty(self , real , fake):\n",
    "        alpha = torch.rand(real.shape[0], 1, 1, 1).to(self.device)\n",
    "        interpolates = (alpha * real + (1 - alpha) * fake).requires_grad_(True)\n",
    "        disc_interpolates = self.model.critic(interpolates)\n",
    "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(self.device),\n",
    "                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return gradient_penalty\n",
    "\n",
    "    def train_step(self) :\n",
    "        total_loss_critic = 0\n",
    "        total_loss_gen = 0\n",
    "        for i , (data , _) in enumerate(self.dataloader):\n",
    "            data = data.to(self.device)\n",
    "            self.optim_critc.zero_grad()\n",
    "            self.optim_gen.zero_grad()\n",
    "            z = self.latent_sampler(data.shape[0]).to(device=self.device)\n",
    "            gen_data = self.model.gen(z).detach()\n",
    "            gen_y   = self.model.critic(gen_data) \n",
    "            real_y = self.model.critic(data)\n",
    "            loss_critic = self.W_loss_critic(real_y , gen_y) + self.lambda_ * self.gradient_penalty(data , gen_data)\n",
    "            loss_critic.backward()\n",
    "            self.optim_critc.step()\n",
    "           # self.noramlize_weights()\n",
    "\n",
    "            if( i% 5 == 0):\n",
    "                z = self.latent_sampler(data.shape[0]).to(device=self.device)\n",
    "            \n",
    "                gen_data = self.model.gen(z)\n",
    "                gen_y = self.model.critic(gen_data)\n",
    "                loss_gen = -torch.mean(gen_y)\n",
    "                loss_gen.backward()\n",
    "                self.optim_gen.step()\n",
    "                \n",
    "                total_loss_gen += loss_gen.item()\n",
    "            total_loss_critic += loss_critic.item()\n",
    "            \n",
    "        return total_loss_critic/len(self.dataloader) , total_loss_gen/len(self.dataloader)\n",
    "    \n",
    "\n",
    "    def show(self , nx = 10 , e = 0 , images = None):\n",
    "        if(images is None):\n",
    "            images = self.generate_images(nx)\n",
    "        images  = [images[i].permute(1,2,0).detach().cpu().numpy() for i in range(images.shape[0])]\n",
    "        plt.figure(figsize=(3*nx, 2*nx))  # Adjust the size as needed\n",
    "\n",
    "        # Loop through the images and display each one\n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(nx//5 + nx%5, 5, i + 1)  # Change '1, 5' to the desired grid layout\n",
    "            plt.imshow((image * 255).astype(np.uint8))\n",
    "            plt.axis('off')  # This hides the axis\n",
    "\n",
    "        plt.show()\n",
    "        plt.savefig(f\"generated_{e}.png\")\n",
    "\n",
    "    def generate_images(self , number = 5):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            z = self.latent_sampler(number).to(device=self.device)\n",
    "            images = self.model.gen(z)\n",
    "            return images\n",
    "        \n",
    "    def train(self , starting = 0):\n",
    "        for epoch in range(starting , self.epochs):\n",
    "            loss_critic , loss_gen = self.train_step()\n",
    "            print(f\"Epoch {epoch} Generator Loss {loss_gen} Critic loss {loss_critic}\")\n",
    "            if(epoch%50 == 0):\n",
    "               self.checkpoint(epoch)\n",
    "            # if(epoch%5 == 0):\n",
    "            #     self.show()\n",
    "\n",
    "    def checkpoint(self , epoch):\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_critic_state_dict': self.optim_critc.state_dict(),\n",
    "            'optimizer_gen_state_dict' : self.optim_gen.state_dict(),\n",
    "            'epoch': epoch \n",
    "        }, f'newFolder/checkpoint{epoch}.pth')\n",
    "\n",
    "    def resume(self , path , iterations):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optim_critc.load_state_dict(checkpoint['optimizer_critic_state_dict'])\n",
    "        self.optim_gen.load_state_dict(checkpoint['optimizer_gen_state_dict'])\n",
    "        epoch = checkpoint['epoch']+1\n",
    "        self.epochs += iterations\n",
    "        self.train(epoch)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DCGan(input_dims , output_dims=1).to(device=device)\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optim_critc = torch.optim.RMSprop(model.critic.parameters() , learning_rate)\n",
    "optim_gen = torch.optim.RMSprop(model.gen.parameters() , learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DCTrainer(model , dataloader , optim_critic=optim_critc, optim_gen=optim_gen , epochs=epochs , device = device , latent_dims=input_dims  ,lambda_=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622086/1863427479.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850 Generator Loss 0.003102728317296782 Critic loss 9.977038893588754\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnewFolder/checkpoint850.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 119\u001b[0m, in \u001b[0;36mDCTrainer.resume\u001b[0;34m(self, path, iterations)\u001b[0m\n\u001b[1;32m    117\u001b[0m epoch \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m iterations\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 97\u001b[0m, in \u001b[0;36mDCTrainer.train\u001b[0;34m(self, starting)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m , starting \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(starting , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m---> 97\u001b[0m         loss_critic , loss_gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Generator Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_gen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Critic loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_critic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "Cell \u001b[0;32mIn[33], line 49\u001b[0m, in \u001b[0;36mDCTrainer.train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_critc\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_gen\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 49\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     50\u001b[0m gen_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgen(z)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     51\u001b[0m gen_y   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcritic(gen_data) \n",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m, in \u001b[0;36mDCTrainer.latent_sampler\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlatent_sampler\u001b[39m(\u001b[38;5;28mself\u001b[39m ,batch_size ):\n\u001b[0;32m---> 15\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmvn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m samples\n",
      "File \u001b[0;32m/raid/scratch/gourishanker/Presentation/Placements/GANs/GANS_env/lib/python3.12/site-packages/torch/distributions/distribution.py:166\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03mGenerates a sample_shape shaped sample or sample_shape shaped batch of\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03msamples if the distribution parameters are batched.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/scratch/gourishanker/Presentation/Placements/GANs/GANS_env/lib/python3.12/site-packages/torch/distributions/multivariate_normal.py:243\u001b[0m, in \u001b[0;36mMultivariateNormal.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    241\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape)\n\u001b[1;32m    242\u001b[0m eps \u001b[38;5;241m=\u001b[39m _standard_normal(shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m \u001b[43m_batch_mv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbroadcasted_scale_tril\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/scratch/gourishanker/Presentation/Placements/GANs/GANS_env/lib/python3.12/site-packages/torch/distributions/multivariate_normal.py:23\u001b[0m, in \u001b[0;36m_batch_mv\u001b[0;34m(bmat, bvec)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_batch_mv\u001b[39m(bmat, bvec):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Performs a batched matrix-vector product, with compatible but different batch shapes.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    just ones which can be broadcasted.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.resume(\"newFolder/checkpoint850.pth\" , 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(5  ,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.shape)"
   ]
  }
 ]}